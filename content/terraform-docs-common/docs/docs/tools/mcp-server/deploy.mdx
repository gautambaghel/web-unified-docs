---
page_title: Deploy the Terraform model context protocol (MCP) server 
description: |-
 Learn how to deploy the Terraform MCP server, which helps you write configuration using LLM responses sourced from the Terraform registry.
---

# Deploy the Terraform MCP server

The Terraform Model Context Protocol (MCP) server enables AI models to generate Terraform configuration using up-to-date information from the Terraform registry. This page explains how to install, configure, and integrate the server with your AI client.

@include 'beta.mdx'

## Overview

The Terraform MCP server is a specialized service that provides AI models with access to current Terraform provider documentation and module information. You can deploy the server in two environments:

- **Local deployment**: Run the server on your workstation using `stdio` mode for direct communication through standard input/output
- **Remote deployment**: Run the server on a remote instance using `streamable-http` mode for network-based communication

## Installation methods

Choose from three installation options based on your environment and preferences:

| Method | Best for | Requirements |
|--------|----------|--------------|
| [Docker](#docker) | Most users, consistent environments | Docker Engine v20.10.21+ or Docker Desktop v4.14.0+ |
| [Compiled binary](#compiled-binary) | Lightweight deployments, specific OS needs | Compatible operating system |
| [Source installation](#install-from-source) | Development, customization | Go development environment |

### Docker

Docker provides the most reliable and consistent way to run the Terraform MCP server across different environments.

#### Prerequisites

You need one of the following Docker distributions:

- Docker Engine v20.10.21+
- Docker Desktop v4.14.0+

Ensure Docker is installed and running on your system. Refer to the [Docker documentation](https://docs.docker.com/desktop) for installation instructions.

#### Client integration

Choose your AI client for specific configuration instructions:

<Tabs>

<Tab heading="Visual Studio Code">

**Requirements:**
- [Visual Studio Code](https://code.visualstudio.com/docs) installed
- [GitHub Copilot extension](https://code.visualstudio.com/docs/copilot/overview) installed and configured to `Agent` mode
- MCP support enabled (refer to the [VS Code MCP documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers))

**Note:** This configuration also works with [Cursor](https://www.cursor.com). Refer to [Cursor's MCP documentation](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers) for additional details.

**Global installation (all workspaces):**

Add this configuration to your user settings JSON file:

```json
{
  "mcp": {
    "servers": {
      "terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server"
        ]
      }
    }
  }
}
```

**Workspace-specific installation:**

Create an `mcp.json` file in your workspace's `.vscode` directory:

```json
{
  "servers": {
    "terraform": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "hashicorp/terraform-mcp-server"
      ]
    }
  }
}
```

**Verification steps:**

1. Open the chat interface and select **Agent** from the mode settings
1. Click the tools icon to verify that Terraform MCP server tools appear in the available tools list

</Tab>


<Tab heading="Cursor">

**Requirements:**
- [Cursor](https://www.cursor.com) installed
- MCP support configured (refer to [Cursor's MCP documentation](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers))

**Global installation (all workspaces):**

Add this configuration to your user settings JSON file:

```json
{
  "mcp": {
    "servers": {
      "terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server"
        ]
      }
    }
  }
}
```

**Workspace-specific installation:**

Create an `mcp.json` file in your workspace's `.vscode` directory:

```json
{
  "servers": {
    "terraform": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "hashicorp/terraform-mcp-server"
      ]
    }
  }
}
```

**Verification steps:**

1. Open the chat pane and select **Chat Settings** from the ellipses menu
1. Choose **Agent** from the **Default new chat mode** drop-down menu
1. Select **MCP** from the **Cursor Settings** sidebar to verify that Terraform MCP server tools are enabled

</Tab>

<Tab heading="Claude Desktop">

**Requirements:**
- [Claude Desktop](https://support.anthropic.com/en/articles/10065433-installing-claude-for-desktop) installed
- MCP support configured (refer to [Claude Desktop's MCP documentation](https://modelcontextprotocol.io/quickstart/user))

**Configuration:**

Create an `mcp.json` file with the following configuration:
 
```json
{
  "mcpServers": {
    "servers": {
      "hcp-terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server:<version>"
        ]
      }
    }
  }
}
```

**Verification steps:**

1. Open the chat pane and select the **search and tools** slider icon at the bottom left
1. Click **terraform-mcp-server** to verify that all tools are enabled and accessible

</Tab>

<Tab heading="Amazon Q">

**Requirements:**
- [Amazon Q](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html) installed
- MCP support configured (refer to [Amazon Q's MCP documentation](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/qdev-mcp.html))

**Configuration:**

Create an `mcp.json` file with the following configuration:
 
```json
{
  "mcpServers": {
    "servers": {
      "hcp-terraform": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "hashicorp/terraform-mcp-server:<version>"
        ]
      }
    }
  }
}
```

</Tab>

</Tabs>

### Compiled binary

The compiled binary option provides a lightweight installation without Docker dependencies. This method is ideal when you want to minimize resource usage or work in environments with restricted container access.

**Download and installation:**

1. Visit the [release library](https://releases.hashicorp.com/terraform-mcp-server) to find the appropriate binary for your operating system and architecture
1. Download the binary to your preferred location
1. Configure your AI client with the binary path

**Client configuration:**

Add this configuration to your client settings:

```json
{
  "mcp": {
    "servers": {
      "terraform": {
        "command": "/path/to/terraform-mcp-server",
        "args": ["stdio"]
      }
    }
  }
}
```

Replace `/path/to/terraform-mcp-server` with the actual path to your downloaded binary.

### Install from source

Installing from source gives you access to the latest features and allows for customization. This method requires a Go development environment.

**Installation options:**

**Latest stable release:**
```shell-session
$ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@latest
```

**Development version (main branch):**
```shell-session
$ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@main
```

**Client configuration:**

After installation, add this configuration to your client:

```json
{
  "mcp": {
    "servers": {
      "terraform": {
        "command": "/path/to/terraform-mcp-server",
        "args": ["stdio"]
      }
    }
  }
}
```

The binary location depends on your Go installation and `GOPATH` configuration. Use `which terraform-mcp-server` to find the installed binary path.

## Configuration options

### Transport protocols

The Terraform MCP server supports multiple communication methods to fit different deployment scenarios:

#### Stdio transport (default)

**Best for:** Local development and direct integration with MCP clients

**How it works:** Uses standard input/output for JSON-RPC message communication

**Usage:** This transport is automatically used when no specific transport mode is configured

#### StreamableHTTP transport

**Best for:** Remote deployments, distributed setups, and production environments

**How it works:** HTTP-based transport with support for both direct HTTP requests and Server-Sent Events (SSE) streams

**Key features:**
- **Primary endpoint:** `http://{hostname}:8080/mcp`
- **Health monitoring:** `http://{hostname}:8080/health`
- **Flexible configuration:** Customizable host, port, and endpoint paths

**Quick setup:** Set the environment variable `TRANSPORT_MODE=streamable-http` to enable

### Environment variables

Configure the server behavior using these environment variables:

| Variable | Purpose | Default Value | Example |
|----------|---------|---------------|---------|
| `TRANSPORT_MODE` | Communication protocol | `stdio` | `streamable-http` |
| `TRANSPORT_HOST` | HTTP server binding address | `127.0.0.1` | `0.0.0.0` |
| `TRANSPORT_PORT` | HTTP server port | `8080` | `3000` |
| `MCP_ENDPOINT` | HTTP endpoint path | `/mcp` | `/api/mcp` |
| `MCP_SESSION_MODE` | Session management | `stateful` | `stateless` |
| `MCP_ALLOWED_ORIGINS` | CORS allowed origins | `""` (none) | `https://app.terraform.io` |
| `MCP_CORS_MODE` | CORS policy enforcement | `strict` | `development` |

**Note:** The legacy `TRANSPORT_MODE=http` value is still supported but `streamable-http` is recommended for new deployments.

### Command line interface

Control server behavior directly from the command line:

**Stdio mode (local development):**
```bash
terraform-mcp-server stdio [--log-file /path/to/log]
```

**StreamableHTTP mode (remote deployment):**
```bash
terraform-mcp-server streamable-http \
  [--transport-port 8080] \
  [--transport-host 127.0.0.1] \
  [--mcp-endpoint /mcp] \
  [--log-file /path/to/log]
```

### Session management

When using StreamableHTTP transport, choose the session mode that best fits your deployment architecture:

#### Stateful mode (default)

**Best for:** Single-instance deployments, development environments

**Benefits:**
- Maintains context between requests
- Enables complex, multi-step operations
- Provides better user experience for interactive sessions

#### Stateless mode

**Best for:** High-availability deployments, load-balanced environments

**Benefits:**
- Each request is processed independently
- Supports horizontal scaling
- Works well with load balancers and container orchestration

**Enable stateless mode:**
```bash
export MCP_SESSION_MODE=stateless
```

### CORS configuration

Control cross-origin requests when using HTTP transport:

- **`strict`** (default): Only allows same-origin requests
- **`development`**: Permissive CORS for development environments
- **`disabled`**: No CORS restrictions (use with caution)

## Next steps

You have successfully deployed the Terraform MCP server. The server is now ready to enhance your AI model's ability to generate accurate Terraform configurations using current provider documentation and module information.

**Start using the server:**
- Begin prompting your AI model about Terraform configurations
- The server provides access to up-to-date provider documentation
- Ask for help with specific Terraform resources and modules

**Learn more:**
- Refer to [Prompt an AI model](/terraform/docs/tools/mcp-server/prompt) for guidance on effective prompting techniques
- Explore advanced configuration options for your specific deployment needs